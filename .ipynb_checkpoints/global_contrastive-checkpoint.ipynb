{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a19eb6-1a11-4b67-b397-d1e736a4531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, glob\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import manifold, datasets, metrics\n",
    "import pandas as pd\n",
    "\n",
    "def KLdivergence(x, y):\n",
    "  \"\"\"Compute the Kullback-Leibler divergence between two multivariate samples.\n",
    "  Parameters\n",
    "  ----------\n",
    "  x : 2D array (n,d)\n",
    "    Samples from distribution P, which typically represents the true\n",
    "    distribution.\n",
    "  y : 2D array (m,d)\n",
    "    Samples from distribution Q, which typically represents the approximate\n",
    "    distribution.\n",
    "  Returns\n",
    "  -------\n",
    "  out : float\n",
    "    The estimated Kullback-Leibler divergence D(P||Q).\n",
    "  References\n",
    "  ----------\n",
    "  PÃ©rez-Cruz, F. Kullback-Leibler divergence estimation of\n",
    "  continuous distributions IEEE International Symposium on Information\n",
    "  Theory, 2008.\n",
    "  \"\"\"\n",
    "  from scipy.spatial import cKDTree as KDTree\n",
    "\n",
    "  # Check the dimensions are consistent\n",
    "  x = np.atleast_2d(x)\n",
    "  y = np.atleast_2d(y)\n",
    "\n",
    "  n,d = x.shape\n",
    "  m,dy = y.shape\n",
    "\n",
    "  assert(d == dy)\n",
    "\n",
    "\n",
    "  # Build a KD tree representation of the samples and find the nearest neighbour\n",
    "  # of each point in x.\n",
    "  xtree = KDTree(x)\n",
    "  ytree = KDTree(y)\n",
    "\n",
    "  # Get the first two nearest neighbours for x, since the closest one is the\n",
    "  # sample itself.\n",
    "  r = xtree.query(x, k=2, eps=.01, p=2)[0][:,1]\n",
    "  s = ytree.query(x, k=1, eps=.01, p=2)[0]\n",
    "\n",
    "  # There is a mistake in the paper. In Eq. 14, the right side misses a negative sign\n",
    "  # on the first term of the right hand side.\n",
    "  return -np.log(r/s).sum() * d / n + np.log(m / (n - 1.))\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "gpu = True\n",
    "\n",
    "# data_root = '/workspace/Data/womac4/full/'\n",
    "# Change to your data root\n",
    "data_root = '/home/ghc/Dataset/paired_images/womac4/full/'\n",
    "# Change to your log root\n",
    "#log_root = '/run/user/1000/gvfs/smb-share:server=changlab-nas.local,share=data/Data_GHC/OAI/contrastive_checkpoints/'\n",
    "log_root = '/media/ExtHDD01/logs/womac4/'\n",
    "# epoch\n",
    "n_epoch = 160\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32ebff2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m force_no_projection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# force to not use projection, or it will be used if .projection is in a model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m use_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m train_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREADPRJ\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull(), :]\u001b[38;5;241m.\u001b[39mindex)[:]\n\u001b[1;32m     18\u001b[0m test_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREADPRJ\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull(), :]\u001b[38;5;241m.\u001b[39mindex)[:]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#train_index = range(667, 2225)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#test_index = range(667)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('env/csv/womac4_moaks.csv')\n",
    "df = df.loc[df['V$$WOMKP#'] > 0, :]\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "## Models\n",
    "## OPTION 1\n",
    "#prj_name = '/global/1_project128/' # 0.90\n",
    "#prj_name = '/global/1_project256_cosine/' #0.84\n",
    "#prj_name = 'global1_cut1/nce4_down2_0011_ngf24_proj128/'\n",
    "#prj_name = 'global1_cut1/nce4_down2_0011_ngf32_proj128_zcrop16/' # 0.88\n",
    "#prj_name = 'global1_cut1/nce4_down2_0011_ngf24_proj128/' # 0.81\n",
    "#prj_name = 'global1_cut1/nce4_down2_0011_ngf32_proj128_zcrop16_meanpool/' # bad\n",
    "#prj_name = 'global1_cut1/nce4_down4_0011_ngf32_proj32_zcrop16/' # 0.92\n",
    "#prj_name = 'global1_cut1/nce4_down4_0011_ngf32_proj32_zcrop16_moaks/' # 0.936\n",
    "#prj_name = 'global1_cut1/nce4_down4_0011_ngf32_proj32_zcrop16_unpaired/' # 0.857\n",
    "#prj_name = 'global1_cut1/nce4_down4_0011_ngf32_proj32_zcrop16_unpaired_nce0/' # 0.857\n",
    "prj_name = 'global1_cut1/nce4_down4_0011_ngf32_proj32_zcrop16_unpaired_moaks/'\n",
    "force_no_projection = False # force to not use projection, or it will be used if .projection is in a model\n",
    "use_eval = True\n",
    "\n",
    "train_index = list(df.loc[df['READPRJ'].isnull(), :].index)[:]\n",
    "test_index = list(df.loc[df['READPRJ'].notnull(), :].index)[:]\n",
    "\n",
    "#train_index = range(667, 2225)\n",
    "#test_index = range(667)\n",
    " \n",
    "net = torch.load(log_root + prj_name + 'checkpoints/net_g_model_epoch_' + str(n_epoch)  +'.pth', map_location='cpu')\n",
    "if use_eval:\n",
    "    net = net.eval()\n",
    "\n",
    "if gpu:\n",
    "    net = net.cuda()\n",
    "pool = nn.AdaptiveMaxPool3d(output_size=(1, 1, 1))\n",
    "try:\n",
    "    projection = net.projection.cpu()\n",
    "    print('With projection')\n",
    "except:\n",
    "    projection = None\n",
    "    print('No projection')\n",
    "print('go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8c2e2-24dc-467c-a3cd-d7318c1a1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = sorted(glob.glob(data_root + 'ap/*'))\n",
    "blist = sorted(glob.glob(data_root + 'bp/*'))\n",
    "print(len(alist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a36df-2001-4f72-b4c5-4df267dbde70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all = []\n",
    "for i in range(2225):\n",
    "    if (i % 100) == 0:\n",
    "        print(i)\n",
    "    ax = alist[i*23 : (i+1)*23]\n",
    "    bx = blist[i*23 : (i+1)*23]\n",
    "    ax = [tiff.imread(x) for x in ax]\n",
    "    bx = [tiff.imread(x) for x in bx]\n",
    "    ax = np.stack(ax, 0)\n",
    "    bx = np.stack(bx, 0)\n",
    "    ax = ax / ax.max()\n",
    "    bx = bx / bx.max()\n",
    "    ax = torch.from_numpy(ax).float()\n",
    "    bx = torch.from_numpy(bx).float()\n",
    "    ax = ax.unsqueeze(1)\n",
    "    bx = bx.unsqueeze(1)\n",
    "    if gpu:\n",
    "        ax = ax.cuda()\n",
    "    ax = net(ax, alpha=1, method='encode')[-1].detach().cpu()\n",
    "    if gpu:\n",
    "        bx = bx.cuda()\n",
    "    bx = net(bx, alpha=1, method='encode')[-1].detach().cpu()\n",
    "    ax = ax.permute(1, 2, 3, 0).unsqueeze(0)\n",
    "    bx = bx.permute(1, 2, 3, 0).unsqueeze(0)\n",
    "    if i <= -200:\n",
    "        ax = ax.permute(4, 1, 2, 3, 0)\n",
    "        ax = pool(ax)[:, :, 0, 0, 0]\n",
    "        bx = bx.permute(4, 1, 2, 3, 0)\n",
    "        bx = pool(bx)[:, :, 0, 0, 0]\n",
    "    else:\n",
    "        ax = pool(ax)[:, :, 0, 0, 0]\n",
    "        bx = pool(bx)[:, :, 0, 0, 0]\n",
    "    if (projection is not None) and (~force_no_projection):\n",
    "        ax = projection(ax).detach().cpu()\n",
    "        bx = projection(bx).detach().cpu()\n",
    "    all.append(ax)\n",
    "    all.append(bx)\n",
    "    del ax\n",
    "    del bx\n",
    "all = torch.cat(all, 0)\n",
    "all = all.numpy()\n",
    "print(all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('f1.npy', all)\n",
    "#all = np.load('f0.npy')\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "train_index = [2 * x for x in train_index] + [2 * x + 1 for x in train_index]\n",
    "test_index = [2 * x for x in test_index] + [2 * x + 1 for x in test_index]\n",
    "\n",
    "labels = np.array([-1, 1] * 2225)\n",
    "\n",
    "\n",
    "# Split dataset into training and testing data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train = all[train_index, :]\n",
    "y_train = labels[train_index]\n",
    "X_test = all[test_index, :]\n",
    "y_test = labels[test_index]\n",
    "\n",
    "\n",
    "# Create a SVM Classifier\n",
    "clf = svm.SVC(kernel='poly', probability=True)  # Linear Kernel\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute AUC Score\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC Score:\", auc_score)\n",
    "\n",
    "\n",
    "## torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "\n",
    "# SVM Model\n",
    "class LinearSVM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearSVM, self).__init__()\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = LinearSVM()\n",
    "\n",
    "# Loss and Optimizer\n",
    "def hinge_loss(output, target):\n",
    "    return torch.mean(torch.clamp(1 - output.t() * target, min=0))\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train).squeeze()\n",
    "    loss = hinge_loss(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Testing the model (assuming you have X_test and Y_test)\n",
    "with torch.no_grad():\n",
    "     output = model(X_test).squeeze()\n",
    "     print(output)\n",
    "     prediction = torch.sign(output)\n",
    "     accuracy = (prediction == y_test).float().mean()\n",
    "     print(f'Accuracy: {accuracy.item()}')\n",
    "     output = torch.sigmoid(model(X_train).squeeze())\n",
    "     auc_score = roc_auc_score(y_train.detach().numpy(), output.detach().numpy())\n",
    "     print(auc_score)\n",
    "print('over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4593def-d55c-47bd-adab-7f6f857aa649",
   "metadata": {},
   "outputs": [],
   "source": [
    "e0 = reducer.fit_transform(all)\n",
    "e1 = manifold.TSNE(n_components=1, init='random', random_state=5, verbose=1).fit_transform(all)\n",
    "e2 = manifold.TSNE(n_components=2, init='random', random_state=5, verbose=1).fit_transform(all)\n",
    "print(all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c6828-8047-4ebe-82ed-0296e8c675ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e = e0#[:23*5*2, :]\n",
    "plt.scatter(e[::2, 0], e[::2, 1], s=0.5*np.ones(e.shape[0] // 2))\n",
    "plt.scatter(e[1::2, 0], e[1::2, 1], s=0.5*np.ones(e.shape[0] // 2))\n",
    "# I was trying to plot the center of group here but as you can see, it's not always meaningful\n",
    "plt.scatter(e[::2, 0].mean(0), e[::2, 1].mean(0), s=20*np.ones(1))\n",
    "plt.scatter(e[1::2, 0].mean(0), e[1::2, 1].mean(0), s=20*np.ones(1))\n",
    "plt.show()\n",
    "try:\n",
    "    e = e2\n",
    "    plt.scatter(e[::2, 0], e[::2, 1], s=0.5*np.ones(e.shape[0] // 2))\n",
    "    plt.scatter(e[1::2, 0], e[1::2, 1], s=0.5*np.ones(e.shape[0] // 2))\n",
    "    # I was trying to plot the center of group here but as you can see, it's not always meaningful\n",
    "    plt.scatter(e[::2, 0].mean(0), e[::2, 1].mean(0), s=20*np.ones(1))\n",
    "    plt.scatter(e[1::2, 0].mean(0), e[1::2, 1].mean(0), s=20*np.ones(1))\n",
    "    plt.show()\n",
    "except:\n",
    "    e = e1\n",
    "    plt.scatter(e[::2, 0], np.random.rand(e[::2,0].shape[0]), s=0.5*np.ones(e.shape[0] // 2))\n",
    "    plt.scatter(e[1::2, 0], np.random.rand(e[::2,0].shape[0]), s=0.5*np.ones(e.shape[0] // 2))\n",
    "    # I was trying to plot the center of group here but as you can see, it's not always meaningful\n",
    "    plt.ylim(-5, 5)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe75a5-189c-4cee-93d8-b170a4f7edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl = KLdivergence(all[::2, :], all[1::2, :])\n",
    "print(kl)\n",
    "kl = KLdivergence(e1[::2, :], e1[1::2, :])\n",
    "print(kl)\n",
    "auc = metrics.roc_auc_score(np.concatenate([0 * np.ones(e1.shape[0] // 2), 1 * np.ones(e1.shape[0] // 2)]), np.concatenate([e1[::2, 0], e1[1::2, 0]]))\n",
    "print(prj_name)\n",
    "print(auc)\n",
    "e = e1\n",
    "plt.scatter(e[::2, 0], np.random.rand(e[::2,0].shape[0]), s=0.5*np.ones(e.shape[0] // 2))\n",
    "plt.scatter(e[1::2, 0], np.random.rand(e[::2,0].shape[0]), s=0.5*np.ones(e.shape[0] // 2))\n",
    "# I was trying to plot the center of group here but as you can see, it's not always meaningful\n",
    "plt.ylim(-5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c035d645-60dc-40a4-b3af-f14275439a94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 1:\n",
    "    plt.figure(figsize=(20,12))\n",
    "    e = e0\n",
    "    eA = e[::2, :]\n",
    "    eB = e[1::2, :]\n",
    "    plt.scatter(e[::2, 0], e[::2, 1], s=2*np.ones(e.shape[0] // 2))\n",
    "    plt.scatter(e[1::2, 0], e[1::2, 1], s=2*np.ones(e.shape[0] // 2))\n",
    "    for i in range(200):\n",
    "        plt.arrow(eA[i, 0], eA[i, 1], eB[i, 0] - eA[i, 0], eB[i, 1] - eA[i, 1], alpha=0.6, linewidth=0.1, width=0.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf0e2ad",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
